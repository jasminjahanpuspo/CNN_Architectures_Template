{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "V28",
      "mount_file_id": "15TJ_It2NuS3NhcUx7NvH1IP1xZ3Cq_cI",
      "authorship_tag": "ABX9TyPAWojSOtQ/M7FKbymwd0XF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasminjahanpuspo/CNN_Architectures_Template/blob/main/K_fold_EnsembleNet(3_rich_model).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YJDvqB5ghjz1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense\n",
        "from keras.preprocessing import image_dataset_from_directory\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "WBRm00ATjy6A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "import glob as gb\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D ,LeakyReLU\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Average"
      ],
      "metadata": {
        "id": "gChOfkttotyR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your parameters\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)  # Adjust this according to your model requirements\n",
        "N_FOLDS = 5"
      ],
      "metadata": {
        "id": "FUychTC-j1BI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Define the directories for training, testing, and validation\n",
        "train_directory = '/content/drive/MyDrive/MIAS/train'\n",
        "test_directory = '/content/drive/MyDrive/MIAS/test'\n",
        "valid_directory = '/content/drive/MyDrive/MIAS/val'\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    train_directory,\n",
        "    shuffle=True,\n",
        "    labels='inferred',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    test_directory,\n",
        "    shuffle=False,\n",
        "    labels='inferred',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "val_dataset = image_dataset_from_directory(\n",
        "    valid_directory,\n",
        "    shuffle=True,\n",
        "    labels='inferred',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    seed=42\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrasPtDyi6Kf",
        "outputId": "6570f114-b1b2-4737-b30f-48f47ffca513"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3294 files belonging to 2 classes.\n",
            "Found 573 files belonging to 2 classes.\n",
            "Found 573 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset = image_dataset_from_directory(\n",
        "    valid_directory,\n",
        "    shuffle=True,\n",
        "    labels='inferred',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "dpyb3RFwpNuA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f6d9863-cbe0-441b-dbaf-d90d8dc48ff6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 573 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A919AVHqi731"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "26vO_jxnjGe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained models\n",
        "model_1 = load_model('/content/drive/MyDrive/MIAS/BC_Code/inceptiov3/inceptionv3-27-0.9721.hdf5')\n",
        "model_2 = load_model('/content/drive/MyDrive/MIAS/BC_Code/efficientnetb0/efficientnetbo-08-0.9948.hdf5')\n",
        "model_3 = load_model('/content/drive/MyDrive/MIAS/BC_Code/oldefficientnetb3/efficientnetb3-14-0.9965.hdf5')\n"
      ],
      "metadata": {
        "id": "KcuLgaKXjIlf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Meta Learner Logistic Regression**"
      ],
      "metadata": {
        "id": "o3dOHwxqj6JI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Prepare data (flatten and extract from the dataset for stacking)\n",
        "X_train = np.concatenate([x for x, _ in train_dataset], axis=0)\n",
        "y_train = np.concatenate([y for _, y in train_dataset], axis=0)\n",
        "\n",
        "X_test = np.concatenate([x for x, _ in test_dataset], axis=0)\n",
        "y_test = np.concatenate([y for _, y in test_dataset], axis=0)\n"
      ],
      "metadata": {
        "id": "-LJkTTXSjLKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions from base models\n",
        "def get_model_predictions(model, X):\n",
        "    return model.predict(X)"
      ],
      "metadata": {
        "id": "IgBRVazzjMt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds_model_1_train = get_model_predictions(model_1, X_train)\n",
        "preds_model_2_train = get_model_predictions(model_2, X_train)\n",
        "#preds_model_3_train = get_model_predictions(model_3, X_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33dXJoaajOqv",
        "outputId": "00a67744-80b7-4011-a2c1-827a3caec270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "103/103 [==============================] - 23s 210ms/step\n",
            "103/103 [==============================] - 71s 661ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For test data\n",
        "preds_model_1_test = get_model_predictions(model_1, X_test)\n",
        "preds_model_2_test = get_model_predictions(model_2, X_test)\n",
        "#preds_model_3_test = get_model_predictions(model_3, X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1WCtwqdjQJH",
        "outputId": "d54f3d00-2671-4db3-d0e8-fd9066b6c80c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 4s 207ms/step\n",
            "18/18 [==============================] - 12s 664ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate predictions as features for meta-learner\n",
        "train_meta_features = np.concatenate(\n",
        "    [preds_model_1_train, preds_model_2_train ], axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "KdeOfOSvjRb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_meta_features = np.concatenate(\n",
        "    [preds_model_1_test, preds_model_2_test], axis=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "oXQ5k3OBjSwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a simple meta-learner (Logistic Regression or any other ML model)\n",
        "meta_learner = LogisticRegression()\n",
        "meta_learner.fit(train_meta_features, y_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "xLB6UTm3jT7O",
        "outputId": "c1d9fe9d-2485-432f-d43d-893de03a600b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on test data\n",
        "meta_predictions = meta_learner.predict(test_meta_features)\n"
      ],
      "metadata": {
        "id": "QmM_dBybjVH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the stacking model\n",
        "test_accuracy = accuracy_score(y_test, meta_predictions)\n",
        "print(f\"Stacking Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWBEDcL8jW1o",
        "outputId": "f6cec882-aa13-4751-fec9-468090b19a72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Test Accuracy: 0.0140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Meta Learner XGBoost**\n"
      ],
      "metadata": {
        "id": "D_CrDStzkA7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pip install xgboost\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OKtaZj3kFN4",
        "outputId": "23f2324c-5bf4-47e2-e342-087ce76ddb06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xgboost\n",
            "  Downloading xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n",
            "Downloading xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
            "Successfully installed nvidia-nccl-cu12-2.23.4 xgboost-2.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "4ON8XYjhkNBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train the XGBoost meta-learner\n",
        "meta_learner_xgb = xgb.XGBClassifier(\n",
        "    n_estimators=200,        # Number of trees\n",
        "    learning_rate=0.0001,      # Learning rate for boosting\n",
        "    max_depth=5,             # Maximum depth of the trees\n",
        "    random_state=42,         # Reproducibility\n",
        "    use_label_encoder=False, # XGBoost option to avoid label encoder warning\n",
        "    eval_metric='logloss'    # XGBoost default metric\n",
        ")\n",
        "\n",
        "# Fit the meta-learner on the base model predictions\n",
        "meta_learner_xgb.fit(train_meta_features, y_train)\n",
        "\n",
        "# Predict on the test set using the XGBoost meta-learner\n",
        "y_pred_xgb = meta_learner_xgb.predict(test_meta_features)\n",
        "\n",
        "# Evaluate the XGBoost meta-learner\n",
        "stacking_test_accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "print(f\"Stacking Test Accuracy with XGBoost: {stacking_test_accuracy_xgb:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU1Ys7hGkPci",
        "outputId": "6f30345b-7cc3-44cc-d4c8-0ec67f1d807d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [18:36:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Test Accuracy with XGBoost: 0.3822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PADWc0NLkWWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Blending**\n"
      ],
      "metadata": {
        "id": "7ZLNP--Qkf7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Function to get predictions from a model\n",
        "def get_predictions(model, data):\n",
        "    predictions = model.predict(data)\n",
        "    return np.argmax(predictions, axis=1)\n",
        "\n",
        "# Assuming you have loaded your models: model_1, model_2, model_3\n",
        "\n",
        "# Generate predictions from each model\n",
        "predictions_model_1 = get_predictions(model_1, val_dataset)\n",
        "predictions_model_2 = get_predictions(model_2, val_dataset)\n",
        "\n",
        "# Assign weights to the models\n",
        "weights = np.array([0.5, 0.3, 0.2])  # Adjust weights as needed\n",
        "\n",
        "# Combine predictions\n",
        "combined_predictions = (\n",
        "    predictions_model_1 * weights[0] +\n",
        "    predictions_model_2 * weights[1]\n",
        ")\n",
        "\n",
        "# Get final predictions by rounding\n",
        "final_predictions = np.round(combined_predictions).astype(int)\n",
        "\n",
        "# Get true labels from the validation dataset\n",
        "true_labels = []\n",
        "for _, labels in val_dataset:\n",
        "    true_labels.extend(labels.numpy())  # Collect all true labels into a list\n",
        "\n",
        "# Convert true_labels to a numpy array for accuracy calculation\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(true_labels, final_predictions)\n",
        "print(f'Blending Test Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1k6SFpIkiAm",
        "outputId": "ad2cb46b-e314-42df-8305-1ccc886afc99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 18s 805ms/step\n",
            "18/18 [==============================] - 14s 644ms/step\n",
            "Blending Test Accuracy: 0.5689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TpjDUPQ7kmmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Voting**"
      ],
      "metadata": {
        "id": "RvZ0dQRQkrt0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get predictions from a model\n",
        "def get_predictions(model, data):\n",
        "    predictions = model.predict(data)\n",
        "    return np.argmax(predictions, axis=1)\n",
        "\n",
        "# Generate predictions from each model\n",
        "predictions_model_1 = get_predictions(model_1, val_dataset)\n",
        "predictions_model_2 = get_predictions(model_2, val_dataset)\n",
        "\n",
        "# Stack predictions into a single array\n",
        "all_predictions = np.stack([predictions_model_1, predictions_model_2], axis=0)\n",
        "\n",
        "# Perform majority voting\n",
        "final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=all_predictions)\n",
        "\n",
        "# Get true labels from the validation dataset\n",
        "true_labels = []\n",
        "for _, labels in val_dataset:\n",
        "    true_labels.extend(labels.numpy())  # Collect all true labels into a list\n",
        "\n",
        "# Convert true_labels to a numpy array for accuracy calculation\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(true_labels, final_predictions)\n",
        "print(f'Voting Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys_sM_9ckuiu",
        "outputId": "f11c329f-e7ed-435f-c192-7f4fe2985c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 4s 205ms/step\n",
            "18/18 [==============================] - 13s 666ms/step\n",
            "Voting Test Accuracy: 0.5672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**K-fold Voting**"
      ],
      "metadata": {
        "id": "XRr9Ndunk59k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get predictions from a model\n",
        "def get_predictions(model, data):\n",
        "    predictions = model.predict(data)\n",
        "    return np.argmax(predictions, axis=1)\n",
        "\n",
        "# Prepare for K-Fold Cross-Validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Store predictions and true labels\n",
        "all_predictions = []\n",
        "true_labels = []\n",
        "\n",
        "# K-Fold Cross-Validation\n",
        "for train_index, val_index in kf.split(np.arange(len(train_dataset))):\n",
        "    # Create train and validation datasets based on K-Fold indices\n",
        "    train_fold = train_dataset.skip(val_index[0]).take(len(train_index))\n",
        "    val_fold = train_dataset.skip(train_index[0]).take(len(val_index))\n",
        "\n",
        "    # Get predictions from each model\n",
        "    predictions_model_1 = get_predictions(model_1, val_fold)\n",
        "    predictions_model_2 = get_predictions(model_2, val_fold)\n",
        "\n",
        "    # Stack predictions into a single array\n",
        "    fold_predictions = np.stack([predictions_model_1, predictions_model_2], axis=0)\n",
        "\n",
        "    # Perform majority voting\n",
        "    final_predictions = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=fold_predictions)\n",
        "\n",
        "    # Store the predictions and true labels for evaluation\n",
        "    all_predictions.append(final_predictions)\n",
        "\n",
        "    # Get true labels from the validation dataset\n",
        "    for _, labels in val_fold:\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "# Convert true_labels to a numpy array for accuracy calculation\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "# Calculate accuracy\n",
        "final_predictions = np.concatenate(all_predictions)\n",
        "accuracy = accuracy_score(true_labels, final_predictions)\n",
        "print(f'Voting Test Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-J5MDWIk8N8",
        "outputId": "4e807325-7d0d-45fb-d8c2-13088b750d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21/21 [==============================] - 5s 208ms/step\n",
            "21/21 [==============================] - 14s 659ms/step\n",
            "21/21 [==============================] - 5s 211ms/step\n",
            "21/21 [==============================] - 15s 672ms/step\n",
            "21/21 [==============================] - 5s 210ms/step\n",
            "21/21 [==============================] - 15s 679ms/step\n",
            "20/20 [==============================] - 5s 224ms/step\n",
            "20/20 [==============================] - 14s 674ms/step\n",
            "20/20 [==============================] - 5s 220ms/step\n",
            "20/20 [==============================] - 14s 662ms/step\n",
            "Voting Test Accuracy: 0.5167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vj5LvwW_lEIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**k-fold cross validation**"
      ],
      "metadata": {
        "id": "FrH__goElEVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your parameters\n",
        "BATCH_SIZE = 32\n",
        "IMG_SIZE = (224, 224)  # Adjust this according to your model requirements\n",
        "N_FOLDS = 5"
      ],
      "metadata": {
        "id": "6cHTrLWblhmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get predictions from a model\n",
        "def get_predictions(model, data):\n",
        "    predictions = model.predict(data)\n",
        "    return np.argmax(predictions, axis=1)\n",
        "\n",
        "# Prepare for K-Fold Cross-Validation\n",
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "# Store accuracy for each fold\n",
        "accuracies = []\n",
        "\n",
        "# K-Fold Cross-Validation\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(np.arange(len(train_dataset)))):\n",
        "    print(f'Training on fold {fold + 1}...')\n",
        "\n",
        "    # Create train and validation datasets based on K-Fold indices\n",
        "    train_fold = train_dataset.skip(val_index[0]).take(len(train_index))\n",
        "    val_fold = train_dataset.skip(train_index[0]).take(len(val_index))\n",
        "\n",
        "    # Get true labels for validation data\n",
        "    y_val = []\n",
        "    for _, labels in val_fold:\n",
        "        y_val.extend(labels.numpy())\n",
        "\n",
        "    y_val = np.array(y_val)\n",
        "\n",
        "    # Train model on the training fold (you can train one model or multiple here)\n",
        "    # Example with model_1:\n",
        "    history = model_1.fit(\n",
        "        train_fold,\n",
        "        epochs=10,  # Adjust epochs as necessary\n",
        "        validation_data=val_fold\n",
        "    )\n",
        "\n",
        "    # Get predictions from the model for the validation fold\n",
        "    predictions = get_predictions(model_1, val_fold)\n",
        "\n",
        "    # Calculate accuracy for this fold\n",
        "    accuracy = accuracy_score(y_val, predictions)\n",
        "    accuracies.append(accuracy)\n",
        "    print(f'Fold {fold + 1} Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Calculate mean accuracy across all folds\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "print(f'Mean K-Fold Accuracy: {mean_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hho4LDb3lLMA",
        "outputId": "cbe1fe98-d242-4f22-d506-d4e9e2fd0828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on fold 1...\n",
            "Epoch 1/10\n",
            "82/82 [==============================] - 28s 298ms/step - loss: 0.2748 - accuracy: 0.9505 - val_loss: 0.1381 - val_accuracy: 0.9568\n",
            "Epoch 2/10\n",
            "82/82 [==============================] - 23s 280ms/step - loss: 0.1733 - accuracy: 0.9447 - val_loss: 0.0171 - val_accuracy: 0.9970\n",
            "Epoch 3/10\n",
            "82/82 [==============================] - 24s 284ms/step - loss: 0.0510 - accuracy: 0.9825 - val_loss: 0.0208 - val_accuracy: 0.9926\n",
            "Epoch 4/10\n",
            "82/82 [==============================] - 24s 281ms/step - loss: 0.0403 - accuracy: 0.9832 - val_loss: 0.0290 - val_accuracy: 0.9851\n",
            "Epoch 5/10\n",
            "82/82 [==============================] - 23s 277ms/step - loss: 0.0338 - accuracy: 0.9874 - val_loss: 0.0163 - val_accuracy: 0.9940\n",
            "Epoch 6/10\n",
            "82/82 [==============================] - 24s 288ms/step - loss: 0.0210 - accuracy: 0.9935 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "82/82 [==============================] - 24s 285ms/step - loss: 0.0212 - accuracy: 0.9912 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "82/82 [==============================] - 24s 289ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "82/82 [==============================] - 24s 287ms/step - loss: 0.0161 - accuracy: 0.9966 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "82/82 [==============================] - 24s 289ms/step - loss: 0.0111 - accuracy: 0.9977 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "21/21 [==============================] - 5s 206ms/step\n",
            "Fold 1 Accuracy: 0.4836\n",
            "Training on fold 2...\n",
            "Epoch 1/10\n",
            "82/82 [==============================] - 24s 286ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "82/82 [==============================] - 24s 287ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "82/82 [==============================] - 24s 282ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 8.3988e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "82/82 [==============================] - 24s 288ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "82/82 [==============================] - 24s 282ms/step - loss: 0.0126 - accuracy: 0.9954 - val_loss: 9.8028e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "82/82 [==============================] - 23s 275ms/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.0045 - val_accuracy: 0.9985\n",
            "Epoch 7/10\n",
            "82/82 [==============================] - 24s 284ms/step - loss: 0.0308 - accuracy: 0.9882 - val_loss: 0.0063 - val_accuracy: 0.9970\n",
            "Epoch 8/10\n",
            "82/82 [==============================] - 24s 285ms/step - loss: 0.0291 - accuracy: 0.9897 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "82/82 [==============================] - 24s 282ms/step - loss: 0.0290 - accuracy: 0.9916 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "82/82 [==============================] - 24s 280ms/step - loss: 0.0414 - accuracy: 0.9848 - val_loss: 0.0055 - val_accuracy: 0.9985\n",
            "21/21 [==============================] - 5s 212ms/step\n",
            "Fold 2 Accuracy: 0.5119\n",
            "Training on fold 3...\n",
            "Epoch 1/10\n",
            "82/82 [==============================] - 24s 285ms/step - loss: 0.0209 - accuracy: 0.9928 - val_loss: 0.0301 - val_accuracy: 0.9911\n",
            "Epoch 2/10\n",
            "82/82 [==============================] - 24s 289ms/step - loss: 0.0152 - accuracy: 0.9931 - val_loss: 5.9983e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "82/82 [==============================] - 24s 284ms/step - loss: 0.0231 - accuracy: 0.9905 - val_loss: 0.0029 - val_accuracy: 0.9985\n",
            "Epoch 4/10\n",
            "82/82 [==============================] - 24s 284ms/step - loss: 0.0165 - accuracy: 0.9928 - val_loss: 5.9022e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "82/82 [==============================] - 24s 286ms/step - loss: 0.0181 - accuracy: 0.9931 - val_loss: 2.3535e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "82/82 [==============================] - 24s 286ms/step - loss: 0.0123 - accuracy: 0.9966 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "82/82 [==============================] - 24s 288ms/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 4.7267e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "82/82 [==============================] - 23s 278ms/step - loss: 0.0181 - accuracy: 0.9947 - val_loss: 3.4246e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "82/82 [==============================] - 24s 285ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 1.8386e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "82/82 [==============================] - 24s 283ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 5.7408e-04 - val_accuracy: 1.0000\n",
            "21/21 [==============================] - 5s 214ms/step\n",
            "Fold 3 Accuracy: 0.4896\n",
            "Training on fold 4...\n",
            "Epoch 1/10\n",
            "71/71 [==============================] - 23s 295ms/step - loss: 0.0204 - accuracy: 0.9938 - val_loss: 0.0119 - val_accuracy: 0.9953\n",
            "Epoch 2/10\n",
            "71/71 [==============================] - 23s 292ms/step - loss: 0.0490 - accuracy: 0.9859 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "71/71 [==============================] - 23s 290ms/step - loss: 0.0243 - accuracy: 0.9903 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "71/71 [==============================] - 23s 291ms/step - loss: 0.0212 - accuracy: 0.9903 - val_loss: 9.7293e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "71/71 [==============================] - 22s 286ms/step - loss: 0.0278 - accuracy: 0.9894 - val_loss: 0.0044 - val_accuracy: 0.9984\n",
            "Epoch 6/10\n",
            "71/71 [==============================] - 23s 293ms/step - loss: 0.0151 - accuracy: 0.9943 - val_loss: 9.5358e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "71/71 [==============================] - 22s 288ms/step - loss: 0.0098 - accuracy: 0.9960 - val_loss: 6.9284e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "71/71 [==============================] - 22s 285ms/step - loss: 0.0195 - accuracy: 0.9943 - val_loss: 0.0030 - val_accuracy: 0.9984\n",
            "Epoch 9/10\n",
            "71/71 [==============================] - 23s 293ms/step - loss: 0.0144 - accuracy: 0.9943 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "71/71 [==============================] - 23s 293ms/step - loss: 0.0182 - accuracy: 0.9947 - val_loss: 8.3144e-04 - val_accuracy: 1.0000\n",
            "20/20 [==============================] - 5s 218ms/step\n",
            "Fold 4 Accuracy: 0.5203\n",
            "Training on fold 5...\n",
            "Epoch 1/10\n",
            "83/83 [==============================] - 24s 289ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 0.0138 - val_accuracy: 0.9953\n",
            "Epoch 2/10\n",
            "83/83 [==============================] - 24s 285ms/step - loss: 0.0177 - accuracy: 0.9932 - val_loss: 5.7047e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "83/83 [==============================] - 24s 281ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 1.1548e-04 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "83/83 [==============================] - 24s 285ms/step - loss: 0.0030 - accuracy: 0.9989 - val_loss: 6.8908e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "83/83 [==============================] - 23s 277ms/step - loss: 0.0057 - accuracy: 0.9974 - val_loss: 5.7301e-04 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "83/83 [==============================] - 24s 285ms/step - loss: 0.0134 - accuracy: 0.9962 - val_loss: 6.3788e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "83/83 [==============================] - 24s 285ms/step - loss: 0.0074 - accuracy: 0.9970 - val_loss: 2.9289e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "83/83 [==============================] - 24s 279ms/step - loss: 0.0243 - accuracy: 0.9944 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "83/83 [==============================] - 24s 284ms/step - loss: 0.0195 - accuracy: 0.9936 - val_loss: 6.2053e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "83/83 [==============================] - 24s 279ms/step - loss: 0.0062 - accuracy: 0.9974 - val_loss: 3.4382e-04 - val_accuracy: 1.0000\n",
            "20/20 [==============================] - 5s 213ms/step\n",
            "Fold 5 Accuracy: 0.4766\n",
            "Mean K-Fold Accuracy: 0.4964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate test accuracy\n",
        "# Get true labels for test data\n",
        "y_test = []\n",
        "for _, labels in test_dataset:\n",
        "    y_test.extend(labels.numpy())\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Get predictions from the model for the test dataset\n",
        "test_predictions = get_predictions(model_1, test_dataset)\n",
        "\n",
        "# Calculate test accuracy\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv3ERqtnlPPH",
        "outputId": "5ee7fe78-1712-4b72-b806-839d7cfbcb51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 4s 210ms/step\n",
            "Test Accuracy: 0.9651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Nx5izdfso1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**K-fold Average Ensemble**"
      ],
      "metadata": {
        "id": "LXo6932DspMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get predictions from a model\n",
        "def get_predictions(model, data):\n",
        "    predictions = model.predict(data)\n",
        "    return np.argmax(predictions, axis=1)\n",
        "\n",
        "# Function to get average predictions from multiple models\n",
        "def get_ensemble_predictions(models, data):\n",
        "    # Get predictions from each model\n",
        "    predictions = [model.predict(data) for model in models]\n",
        "\n",
        "    # Average the predictions\n",
        "    avg_predictions = np.mean(predictions, axis=0)\n",
        "\n",
        "    # Convert averaged predictions to class labels\n",
        "    return np.argmax(avg_predictions, axis=1)\n"
      ],
      "metadata": {
        "id": "8S9pIiaIstOs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming train_dataset and val_dataset are preprocessed datasets\n",
        "# Replace with your own data pipeline\n",
        "N_FOLDS = 5  # Define number of folds\n",
        "\n",
        "# Prepare for K-Fold Cross-Validation\n",
        "kf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "# Store accuracy for each fold for the ensemble\n",
        "ensemble_accuracies = []\n"
      ],
      "metadata": {
        "id": "t0rKqWkWsxxU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Fold Cross-Validation\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(np.arange(len(train_dataset)))):\n",
        "    print(f'Training on fold {fold + 1}...')\n",
        "\n",
        "    # Create train and validation datasets based on K-Fold indices\n",
        "    train_fold = train_dataset.skip(val_index[0]).take(len(train_index))\n",
        "    val_fold = train_dataset.skip(train_index[0]).take(len(val_index))\n",
        "\n",
        "    # Get true labels for validation data\n",
        "    y_val = []\n",
        "    for _, labels in val_fold:\n",
        "        y_val.extend(labels.numpy())\n",
        "\n",
        "    y_val = np.array(y_val)\n",
        "\n",
        "    # Train all models on the training fold\n",
        "    history_model_1 = model_1.fit(\n",
        "        train_fold,\n",
        "        epochs=5,  # Adjust epochs as necessary\n",
        "        validation_data=val_fold,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    history_model_2 = model_2.fit(\n",
        "        train_fold,\n",
        "        epochs=5,\n",
        "        validation_data=val_fold,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    history_model_3 = model_3.fit(\n",
        "        train_fold,\n",
        "        epochs=5,\n",
        "        validation_data=val_fold,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    # Get ensemble predictions for the validation fold\n",
        "    models = [model_1, model_2, model_3]\n",
        "    ensemble_predictions = get_ensemble_predictions(models, val_fold)\n",
        "\n",
        "    # Calculate accuracy for the ensemble model\n",
        "    ensemble_accuracy = accuracy_score(y_val, ensemble_predictions)\n",
        "    ensemble_accuracies.append(ensemble_accuracy)\n",
        "\n",
        "    print(f'Fold {fold + 1} Ensemble Accuracy: {ensemble_accuracy:.4f}')\n",
        "\n",
        "# Calculate mean accuracy across all folds for the ensemble\n",
        "mean_ensemble_accuracy = np.mean(ensemble_accuracies)\n",
        "print(f'Mean K-Fold Ensemble Accuracy: {mean_ensemble_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K-AzP55s03i",
        "outputId": "5db84837-4c08-4ee1-f49f-72034c249a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on fold 1...\n",
            "21/21 [==============================] - 6s 206ms/step\n",
            "21/21 [==============================] - 17s 683ms/step\n",
            "21/21 [==============================] - 17s 687ms/step\n",
            "Fold 1 Ensemble Accuracy: 0.4762\n",
            "Training on fold 2...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Fold Cross-Validation\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(np.arange(len(train_dataset)))):\n",
        "    print(f'Training on fold {fold + 1}...')\n",
        "\n",
        "    # Create train and validation datasets based on K-Fold indices\n",
        "    train_fold = train_dataset.skip(val_index[0]).take(len(train_index))\n",
        "    val_fold = train_dataset.skip(train_index[0]).take(len(val_index))\n",
        "\n",
        "    # Get true labels for validation data\n",
        "    y_val = []\n",
        "    for _, labels in val_fold:\n",
        "        y_val.extend(labels.numpy())\n",
        "\n",
        "    y_val = np.array(y_val)\n",
        "\n",
        "    # Train all models on the training fold\n",
        "    history_model_1 = model_1.fit(\n",
        "        train_fold,\n",
        "        epochs=5,  # Adjust epochs as necessary\n",
        "        validation_data=val_fold,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    history_model_2 = model_2.fit(\n",
        "        train_fold,\n",
        "        epochs=5,\n",
        "        validation_data=val_fold,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    history_model_3 = model_3.fit(\n",
        "        train_fold,\n",
        "        epochs=5,\n",
        "        validation_data=val_fold,\n",
        "        verbose=2\n",
        "    )\n",
        "\n",
        "    # Get ensemble predictions for the validation fold\n",
        "    models = [model_1, model_2, model_3]\n",
        "    ensemble_predictions = get_ensemble_predictions(models, val_fold)\n",
        "\n",
        "    # Calculate accuracy for the ensemble model\n",
        "    ensemble_accuracy = accuracy_score(y_val, ensemble_predictions)\n",
        "    ensemble_accuracies.append(ensemble_accuracy)\n",
        "\n",
        "    print(f'Fold {fold + 1} Ensemble Accuracy: {ensemble_accuracy:.4f}')\n",
        "\n",
        "# Calculate mean accuracy across all folds for the ensemble\n",
        "mean_ensemble_accuracy = np.mean(ensemble_accuracies)\n",
        "print(f'Mean K-Fold Ensemble Accuracy: {mean_ensemble_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAUN9gEGcrvN",
        "outputId": "705230cc-a514-42b3-9cc6-0d512e7c2db1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on fold 1...\n",
            "Epoch 1/5\n",
            "82/82 - 37s - loss: 0.3060 - accuracy: 0.9062 - val_loss: 0.0826 - val_accuracy: 0.9673 - 37s/epoch - 451ms/step\n",
            "Epoch 2/5\n",
            "82/82 - 22s - loss: 0.0891 - accuracy: 0.9630 - val_loss: 0.0192 - val_accuracy: 0.9926 - 22s/epoch - 269ms/step\n",
            "Epoch 3/5\n",
            "82/82 - 22s - loss: 0.0581 - accuracy: 0.9779 - val_loss: 0.0106 - val_accuracy: 0.9985 - 22s/epoch - 272ms/step\n",
            "Epoch 4/5\n",
            "82/82 - 22s - loss: 0.0250 - accuracy: 0.9909 - val_loss: 0.0027 - val_accuracy: 1.0000 - 22s/epoch - 266ms/step\n",
            "Epoch 5/5\n",
            "82/82 - 22s - loss: 0.0304 - accuracy: 0.9920 - val_loss: 0.0192 - val_accuracy: 0.9926 - 22s/epoch - 270ms/step\n",
            "Epoch 1/5\n",
            "82/82 - 98s - loss: 0.9545 - accuracy: 0.6890 - val_loss: 0.5480 - val_accuracy: 0.6548 - 98s/epoch - 1s/step\n",
            "Epoch 2/5\n",
            "82/82 - 83s - loss: 0.4453 - accuracy: 0.8445 - val_loss: 0.0995 - val_accuracy: 0.9613 - 83s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "82/82 - 82s - loss: 0.0797 - accuracy: 0.9775 - val_loss: 0.3644 - val_accuracy: 0.9018 - 82s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "82/82 - 81s - loss: 0.0310 - accuracy: 0.9916 - val_loss: 0.0045 - val_accuracy: 0.9985 - 81s/epoch - 982ms/step\n",
            "Epoch 5/5\n",
            "82/82 - 80s - loss: 0.8693 - accuracy: 0.9200 - val_loss: 0.6802 - val_accuracy: 0.5506 - 80s/epoch - 981ms/step\n",
            "Epoch 1/5\n",
            "82/82 - 97s - loss: 1.6365 - accuracy: 0.9101 - val_loss: 0.8071 - val_accuracy: 0.4896 - 97s/epoch - 1s/step\n",
            "Epoch 2/5\n",
            "82/82 - 83s - loss: 15.8236 - accuracy: 0.4851 - val_loss: 0.6871 - val_accuracy: 0.5744 - 83s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "82/82 - 80s - loss: 0.8134 - accuracy: 0.5050 - val_loss: 0.6829 - val_accuracy: 0.5432 - 80s/epoch - 974ms/step\n",
            "Epoch 4/5\n",
            "82/82 - 79s - loss: 0.7015 - accuracy: 0.5514 - val_loss: 0.6645 - val_accuracy: 0.6176 - 79s/epoch - 969ms/step\n",
            "Epoch 5/5\n",
            "82/82 - 79s - loss: 0.6796 - accuracy: 0.5979 - val_loss: 0.6178 - val_accuracy: 0.6637 - 79s/epoch - 967ms/step\n",
            "21/21 [==============================] - 6s 183ms/step\n",
            "21/21 [==============================] - 16s 626ms/step\n",
            "21/21 [==============================] - 16s 634ms/step\n",
            "Fold 1 Ensemble Accuracy: 0.5045\n",
            "Training on fold 2...\n",
            "Epoch 1/5\n",
            "82/82 - 21s - loss: 0.0210 - accuracy: 0.9928 - val_loss: 0.0061 - val_accuracy: 1.0000 - 21s/epoch - 254ms/step\n",
            "Epoch 2/5\n",
            "82/82 - 21s - loss: 0.0173 - accuracy: 0.9958 - val_loss: 0.0020 - val_accuracy: 1.0000 - 21s/epoch - 255ms/step\n",
            "Epoch 3/5\n",
            "82/82 - 21s - loss: 0.0273 - accuracy: 0.9893 - val_loss: 0.0064 - val_accuracy: 1.0000 - 21s/epoch - 254ms/step\n",
            "Epoch 4/5\n",
            "82/82 - 21s - loss: 0.0165 - accuracy: 0.9939 - val_loss: 0.0013 - val_accuracy: 1.0000 - 21s/epoch - 253ms/step\n",
            "Epoch 5/5\n",
            "82/82 - 20s - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.0021 - val_accuracy: 1.0000 - 20s/epoch - 250ms/step\n",
            "Epoch 1/5\n",
            "82/82 - 79s - loss: 1.6243 - accuracy: 0.5053 - val_loss: 0.6956 - val_accuracy: 0.4494 - 79s/epoch - 962ms/step\n",
            "Epoch 2/5\n",
            "82/82 - 80s - loss: 0.8057 - accuracy: 0.5217 - val_loss: 0.6938 - val_accuracy: 0.4762 - 80s/epoch - 972ms/step\n",
            "Epoch 3/5\n",
            "82/82 - 79s - loss: 2.1694 - accuracy: 0.5259 - val_loss: 0.6914 - val_accuracy: 0.5238 - 79s/epoch - 958ms/step\n",
            "Epoch 4/5\n",
            "82/82 - 80s - loss: 0.7586 - accuracy: 0.5103 - val_loss: 0.6925 - val_accuracy: 0.5223 - 80s/epoch - 972ms/step\n",
            "Epoch 5/5\n",
            "82/82 - 81s - loss: 0.7704 - accuracy: 0.5061 - val_loss: 0.6917 - val_accuracy: 0.5446 - 81s/epoch - 982ms/step\n",
            "Epoch 1/5\n",
            "82/82 - 79s - loss: 0.5760 - accuracy: 0.7050 - val_loss: 0.4846 - val_accuracy: 0.7530 - 79s/epoch - 968ms/step\n",
            "Epoch 2/5\n",
            "82/82 - 82s - loss: 0.4899 - accuracy: 0.7679 - val_loss: 0.4174 - val_accuracy: 0.8006 - 82s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "82/82 - 81s - loss: 0.3773 - accuracy: 0.8449 - val_loss: 0.2982 - val_accuracy: 0.8750 - 81s/epoch - 983ms/step\n",
            "Epoch 4/5\n",
            "82/82 - 81s - loss: 0.3309 - accuracy: 0.8735 - val_loss: 0.2180 - val_accuracy: 0.9018 - 81s/epoch - 992ms/step\n",
            "Epoch 5/5\n",
            "82/82 - 80s - loss: 0.1996 - accuracy: 0.9192 - val_loss: 0.1158 - val_accuracy: 0.9554 - 80s/epoch - 978ms/step\n",
            "21/21 [==============================] - 4s 186ms/step\n",
            "21/21 [==============================] - 14s 646ms/step\n",
            "21/21 [==============================] - 14s 641ms/step\n",
            "Fold 2 Ensemble Accuracy: 0.4583\n",
            "Training on fold 3...\n",
            "Epoch 1/5\n",
            "82/82 - 21s - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.0075 - val_accuracy: 0.9970 - 21s/epoch - 255ms/step\n",
            "Epoch 2/5\n",
            "82/82 - 21s - loss: 0.0100 - accuracy: 0.9958 - val_loss: 0.0046 - val_accuracy: 0.9985 - 21s/epoch - 258ms/step\n",
            "Epoch 3/5\n",
            "82/82 - 21s - loss: 0.0109 - accuracy: 0.9958 - val_loss: 0.0014 - val_accuracy: 1.0000 - 21s/epoch - 261ms/step\n",
            "Epoch 4/5\n",
            "82/82 - 21s - loss: 0.0257 - accuracy: 0.9905 - val_loss: 0.0072 - val_accuracy: 0.9985 - 21s/epoch - 256ms/step\n",
            "Epoch 5/5\n",
            "82/82 - 21s - loss: 0.0133 - accuracy: 0.9954 - val_loss: 6.4078e-04 - val_accuracy: 1.0000 - 21s/epoch - 262ms/step\n",
            "Epoch 1/5\n",
            "82/82 - 83s - loss: 0.7164 - accuracy: 0.5126 - val_loss: 0.6903 - val_accuracy: 0.5268 - 83s/epoch - 1s/step\n",
            "Epoch 2/5\n",
            "82/82 - 83s - loss: 0.6730 - accuracy: 0.5857 - val_loss: 0.5787 - val_accuracy: 0.6920 - 83s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "82/82 - 80s - loss: 64.2802 - accuracy: 0.4958 - val_loss: 0.7534 - val_accuracy: 0.5312 - 80s/epoch - 980ms/step\n",
            "Epoch 4/5\n",
            "82/82 - 83s - loss: 20.1371 - accuracy: 0.4992 - val_loss: 1.5036 - val_accuracy: 0.4807 - 83s/epoch - 1s/step\n",
            "Epoch 5/5\n",
            "82/82 - 79s - loss: 1.4190 - accuracy: 0.4973 - val_loss: 1.3468 - val_accuracy: 0.4747 - 79s/epoch - 962ms/step\n",
            "Epoch 1/5\n",
            "82/82 - 81s - loss: 0.1423 - accuracy: 0.9566 - val_loss: 0.1014 - val_accuracy: 0.9688 - 81s/epoch - 987ms/step\n",
            "Epoch 2/5\n",
            "82/82 - 84s - loss: 0.0912 - accuracy: 0.9714 - val_loss: 0.1077 - val_accuracy: 0.9598 - 84s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "82/82 - 85s - loss: 0.0629 - accuracy: 0.9775 - val_loss: 0.0257 - val_accuracy: 0.9940 - 85s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "82/82 - 82s - loss: 0.0455 - accuracy: 0.9874 - val_loss: 0.0191 - val_accuracy: 0.9926 - 82s/epoch - 1s/step\n",
            "Epoch 5/5\n",
            "82/82 - 83s - loss: 0.0402 - accuracy: 0.9897 - val_loss: 0.0031 - val_accuracy: 1.0000 - 83s/epoch - 1s/step\n",
            "21/21 [==============================] - 4s 188ms/step\n",
            "21/21 [==============================] - 14s 631ms/step\n",
            "21/21 [==============================] - 14s 665ms/step\n",
            "Fold 3 Ensemble Accuracy: 0.4896\n",
            "Training on fold 4...\n",
            "Epoch 1/5\n",
            "71/71 - 20s - loss: 0.0151 - accuracy: 0.9934 - val_loss: 0.0088 - val_accuracy: 0.9953 - 20s/epoch - 288ms/step\n",
            "Epoch 2/5\n",
            "71/71 - 21s - loss: 0.0340 - accuracy: 0.9872 - val_loss: 0.0070 - val_accuracy: 0.9953 - 21s/epoch - 296ms/step\n",
            "Epoch 3/5\n",
            "71/71 - 20s - loss: 0.0507 - accuracy: 0.9824 - val_loss: 0.0055 - val_accuracy: 0.9984 - 20s/epoch - 281ms/step\n",
            "Epoch 4/5\n",
            "71/71 - 21s - loss: 0.0316 - accuracy: 0.9903 - val_loss: 0.0086 - val_accuracy: 0.9969 - 21s/epoch - 293ms/step\n",
            "Epoch 5/5\n",
            "71/71 - 20s - loss: 0.0363 - accuracy: 0.9881 - val_loss: 0.0041 - val_accuracy: 1.0000 - 20s/epoch - 283ms/step\n",
            "Epoch 1/5\n",
            "71/71 - 73s - loss: 1.2960 - accuracy: 0.5093 - val_loss: 1.2537 - val_accuracy: 0.4609 - 73s/epoch - 1s/step\n",
            "Epoch 2/5\n",
            "71/71 - 72s - loss: 1.2135 - accuracy: 0.5093 - val_loss: 1.1807 - val_accuracy: 0.4734 - 72s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "71/71 - 72s - loss: 1.1494 - accuracy: 0.5044 - val_loss: 1.1234 - val_accuracy: 0.4719 - 72s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "71/71 - 72s - loss: 1.0970 - accuracy: 0.5128 - val_loss: 1.0765 - val_accuracy: 0.4750 - 72s/epoch - 1s/step\n",
            "Epoch 5/5\n",
            "71/71 - 71s - loss: 1.0544 - accuracy: 0.5101 - val_loss: 1.0380 - val_accuracy: 0.4688 - 71s/epoch - 999ms/step\n",
            "Epoch 1/5\n",
            "71/71 - 73s - loss: 0.0350 - accuracy: 0.9912 - val_loss: 0.0180 - val_accuracy: 0.9937 - 73s/epoch - 1s/step\n",
            "Epoch 2/5\n",
            "71/71 - 72s - loss: 0.0357 - accuracy: 0.9907 - val_loss: 0.0484 - val_accuracy: 0.9750 - 72s/epoch - 1s/step\n",
            "Epoch 3/5\n",
            "71/71 - 72s - loss: 0.2149 - accuracy: 0.9458 - val_loss: 0.0414 - val_accuracy: 0.9875 - 72s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "71/71 - 73s - loss: 0.0234 - accuracy: 0.9938 - val_loss: 0.0087 - val_accuracy: 0.9969 - 73s/epoch - 1s/step\n",
            "Epoch 5/5\n",
            "71/71 - 74s - loss: 0.0033 - accuracy: 0.9996 - val_loss: 0.0141 - val_accuracy: 0.9953 - 74s/epoch - 1s/step\n",
            "20/20 [==============================] - 4s 187ms/step\n",
            "20/20 [==============================] - 13s 644ms/step\n",
            "20/20 [==============================] - 14s 655ms/step\n",
            "Fold 4 Ensemble Accuracy: 0.5109\n",
            "Training on fold 5...\n",
            "Epoch 1/5\n",
            "83/83 - 21s - loss: 0.0348 - accuracy: 0.9883 - val_loss: 0.0051 - val_accuracy: 0.9984 - 21s/epoch - 248ms/step\n",
            "Epoch 2/5\n",
            "83/83 - 21s - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0067 - val_accuracy: 0.9969 - 21s/epoch - 250ms/step\n",
            "Epoch 3/5\n",
            "83/83 - 21s - loss: 0.0236 - accuracy: 0.9932 - val_loss: 0.0024 - val_accuracy: 1.0000 - 21s/epoch - 254ms/step\n",
            "Epoch 4/5\n",
            "83/83 - 21s - loss: 0.0144 - accuracy: 0.9936 - val_loss: 0.0011 - val_accuracy: 1.0000 - 21s/epoch - 253ms/step\n",
            "Epoch 5/5\n",
            "83/83 - 21s - loss: 0.0080 - accuracy: 0.9970 - val_loss: 0.0017 - val_accuracy: 0.9984 - 21s/epoch - 255ms/step\n",
            "Epoch 1/5\n",
            "83/83 - 82s - loss: 1.0167 - accuracy: 0.4992 - val_loss: 0.9985 - val_accuracy: 0.4906 - 82s/epoch - 983ms/step\n",
            "Epoch 2/5\n",
            "83/83 - 81s - loss: 0.9822 - accuracy: 0.4940 - val_loss: 0.9679 - val_accuracy: 0.4656 - 81s/epoch - 978ms/step\n",
            "Epoch 3/5\n",
            "83/83 - 83s - loss: 0.9529 - accuracy: 0.4955 - val_loss: 0.9401 - val_accuracy: 0.4828 - 83s/epoch - 1s/step\n",
            "Epoch 4/5\n",
            "83/83 - 83s - loss: 0.9280 - accuracy: 0.4977 - val_loss: 0.9177 - val_accuracy: 0.4656 - 83s/epoch - 999ms/step\n",
            "Epoch 5/5\n",
            "83/83 - 85s - loss: 0.9068 - accuracy: 0.4974 - val_loss: 0.8977 - val_accuracy: 0.4734 - 85s/epoch - 1s/step\n",
            "Epoch 1/5\n",
            "83/83 - 82s - loss: 0.0124 - accuracy: 0.9955 - val_loss: 0.0177 - val_accuracy: 0.9969 - 82s/epoch - 992ms/step\n",
            "Epoch 2/5\n",
            "83/83 - 81s - loss: 0.0311 - accuracy: 0.9936 - val_loss: 0.0219 - val_accuracy: 0.9922 - 81s/epoch - 976ms/step\n",
            "Epoch 3/5\n",
            "83/83 - 81s - loss: 0.0127 - accuracy: 0.9962 - val_loss: 0.0050 - val_accuracy: 0.9984 - 81s/epoch - 974ms/step\n",
            "Epoch 4/5\n",
            "83/83 - 83s - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0016 - val_accuracy: 1.0000 - 83s/epoch - 995ms/step\n",
            "Epoch 5/5\n",
            "83/83 - 82s - loss: 0.0223 - accuracy: 0.9917 - val_loss: 0.0650 - val_accuracy: 0.9797 - 82s/epoch - 990ms/step\n",
            "20/20 [==============================] - 5s 198ms/step\n",
            "20/20 [==============================] - 14s 654ms/step\n",
            "20/20 [==============================] - 14s 673ms/step\n",
            "Fold 5 Ensemble Accuracy: 0.4891\n",
            "Mean K-Fold Ensemble Accuracy: 0.4905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the test dataset\n",
        "models = [model_1, model_2, model_3]\n",
        "test_predictions = get_ensemble_predictions(models, test_dataset)\n",
        "\n",
        "# Get true labels for the test dataset\n",
        "y_test = []\n",
        "for _, labels in test_dataset:\n",
        "    y_test.extend(labels.numpy())\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# Calculate accuracy for the test dataset\n",
        "test_accuracy = accuracy_score(y_test, test_predictions)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')"
      ],
      "metadata": {
        "id": "KcdXvw6CtpfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58543fd6-294e-4c1f-9aff-579c5405bd22"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 9s 399ms/step\n",
            "18/18 [==============================] - 12s 659ms/step\n",
            "18/18 [==============================] - 12s 669ms/step\n",
            "Test Accuracy: 0.9895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get true labels for the validation or test set\n",
        "y_true = []\n",
        "for _, labels in val_fold:  # Change val_fold to test_dataset for test data\n",
        "    y_true.extend(labels.numpy())\n",
        "\n",
        "y_true = np.array(y_true)  # Convert to numpy array for easier processing\n"
      ],
      "metadata": {
        "id": "ADwOkNCMvh9h"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ensemble_predictions(models, dataset):\n",
        "    # Create an empty list to store predictions from all models\n",
        "    all_predictions = []\n",
        "\n",
        "    for model in models:\n",
        "        model_predictions = []\n",
        "        for images, _ in dataset:  # Loop through dataset without using labels\n",
        "            predictions = model.predict(images)\n",
        "            model_predictions.append(predictions)\n",
        "        all_predictions.append(np.concatenate(model_predictions))\n",
        "\n",
        "    # Average the predictions from all models (for classification)\n",
        "    averaged_predictions = np.mean(np.array(all_predictions), axis=0)\n",
        "\n",
        "    # Convert averaged predictions into class labels (assuming softmax probabilities)\n",
        "    predicted_labels = np.argmax(averaged_predictions, axis=1)\n",
        "\n",
        "    return predicted_labels\n"
      ],
      "metadata": {
        "id": "Djx0wrhnvkgW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = get_ensemble_predictions(models, val_fold)  # or test_dataset for test set\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMUaBzzKvmoj",
        "outputId": "b8987f12-1f2e-4273-cfeb-3433dc31f082"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 223ms/step\n",
            "1/1 [==============================] - 0s 194ms/step\n",
            "1/1 [==============================] - 0s 196ms/step\n",
            "1/1 [==============================] - 0s 224ms/step\n",
            "1/1 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 0s 200ms/step\n",
            "1/1 [==============================] - 0s 228ms/step\n",
            "1/1 [==============================] - 0s 222ms/step\n",
            "1/1 [==============================] - 0s 227ms/step\n",
            "1/1 [==============================] - 0s 195ms/step\n",
            "1/1 [==============================] - 0s 197ms/step\n",
            "1/1 [==============================] - 0s 202ms/step\n",
            "1/1 [==============================] - 0s 205ms/step\n",
            "1/1 [==============================] - 0s 226ms/step\n",
            "1/1 [==============================] - 0s 189ms/step\n",
            "1/1 [==============================] - 0s 206ms/step\n",
            "1/1 [==============================] - 0s 216ms/step\n",
            "1/1 [==============================] - 0s 203ms/step\n",
            "1/1 [==============================] - 0s 206ms/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 1s 606ms/step\n",
            "1/1 [==============================] - 1s 638ms/step\n",
            "1/1 [==============================] - 1s 596ms/step\n",
            "1/1 [==============================] - 1s 614ms/step\n",
            "1/1 [==============================] - 1s 688ms/step\n",
            "1/1 [==============================] - 1s 654ms/step\n",
            "1/1 [==============================] - 1s 634ms/step\n",
            "1/1 [==============================] - 1s 657ms/step\n",
            "1/1 [==============================] - 1s 610ms/step\n",
            "1/1 [==============================] - 1s 620ms/step\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "1/1 [==============================] - 1s 602ms/step\n",
            "1/1 [==============================] - 1s 665ms/step\n",
            "1/1 [==============================] - 1s 656ms/step\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "1/1 [==============================] - 1s 606ms/step\n",
            "1/1 [==============================] - 1s 569ms/step\n",
            "1/1 [==============================] - 1s 602ms/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "1/1 [==============================] - 1s 592ms/step\n",
            "1/1 [==============================] - 1s 692ms/step\n",
            "1/1 [==============================] - 1s 591ms/step\n",
            "1/1 [==============================] - 1s 631ms/step\n",
            "1/1 [==============================] - 1s 596ms/step\n",
            "1/1 [==============================] - 1s 571ms/step\n",
            "1/1 [==============================] - 1s 685ms/step\n",
            "1/1 [==============================] - 1s 607ms/step\n",
            "1/1 [==============================] - 1s 683ms/step\n",
            "1/1 [==============================] - 1s 575ms/step\n",
            "1/1 [==============================] - 1s 577ms/step\n",
            "1/1 [==============================] - 1s 607ms/step\n",
            "1/1 [==============================] - 1s 665ms/step\n",
            "1/1 [==============================] - 1s 634ms/step\n",
            "1/1 [==============================] - 1s 589ms/step\n",
            "1/1 [==============================] - 1s 673ms/step\n",
            "1/1 [==============================] - 1s 682ms/step\n",
            "1/1 [==============================] - 1s 687ms/step\n",
            "1/1 [==============================] - 1s 585ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "# Detailed classification report (Precision, Recall, F1-score)\n",
        "report = classification_report(y_true, y_pred)\n",
        "print('Classification Report:')\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_NTplxXvpi_",
        "outputId": "0de3a33b-4087-4454-b405-9d87297f1114"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[114 224]\n",
            " [ 90 212]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.34      0.42       338\n",
            "           1       0.49      0.70      0.57       302\n",
            "\n",
            "    accuracy                           0.51       640\n",
            "   macro avg       0.52      0.52      0.50       640\n",
            "weighted avg       0.52      0.51      0.49       640\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize counters for correct and incorrect predictions\n",
        "correct_predictions = 0\n",
        "incorrect_predictions = 0\n",
        "\n",
        "# Loop through the validation data to count correct and incorrect predictions\n",
        "for i, (images, true_label) in enumerate(val_fold):  # or test_dataset\n",
        "    # Get the true label as an index\n",
        "    true_label = np.argmax(true_label.numpy())  # Assuming one-hot encoded\n",
        "    predicted_label = y_pred[i]  # Get predicted label\n",
        "\n",
        "    # Check if the prediction is correct\n",
        "    if true_label == predicted_label:\n",
        "        correct_predictions += 1\n",
        "    else:\n",
        "        incorrect_predictions += 1\n",
        "\n",
        "# Print the counts\n",
        "print(f'Correct Predictions: {correct_predictions}')\n",
        "print(f'Incorrect Predictions: {incorrect_predictions}')\n",
        "\n",
        "# Optionally, print the total predictions and accuracy\n",
        "total_predictions = correct_predictions + incorrect_predictions\n",
        "accuracy = correct_predictions / total_predictions * 100 if total_predictions > 0 else 0\n",
        "print(f'Total Predictions: {total_predictions}')\n",
        "print(f'Accuracy: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpFmLkIVwk91",
        "outputId": "00d03708-717f-4333-a4ff-626434f01c22"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct Predictions: 7\n",
            "Incorrect Predictions: 13\n",
            "Total Predictions: 20\n",
            "Accuracy: 35.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-4Ey0Fh7wlBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Average Ensemble**"
      ],
      "metadata": {
        "id": "bprrzf-zngQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_learning_rate = 0.001 # prefferable lr is 0.0001 or 0.001\n",
        "IMG_SHAPE = IMG_SIZE +(3,)"
      ],
      "metadata": {
        "id": "R1fInDZgoLqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [model_1, model_2]\n",
        "model_input = Input(shape=(224, 224, 3))\n",
        "model_outputs = [model(model_input) for model in models]\n",
        "ensemble_output = Average()(model_outputs)\n",
        "ensemble_model = Model(inputs=model_input, outputs=ensemble_output, name='ensemble')"
      ],
      "metadata": {
        "id": "M_RRzNU5oQb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## customize optimizer as Nadam or Adam\n",
        "ensemble_model.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate=base_learning_rate),\n",
        "                           loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                           metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ibFDlfakoSHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Adjust hyperparameters such as the number of epochs and add early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)"
      ],
      "metadata": {
        "id": "ez3E90R8pHeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot bar chart for demonstrating data size\n",
        "Dataset = []\n",
        "for folder in os.listdir(train_directory):\n",
        "    files = gb.glob(pathname=str(train_directory + \"/\" + folder +\"/*.*\"))\n",
        "    Dataset.append(len(files))"
      ],
      "metadata": {
        "id": "1FI2TR-HoV4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate total number of samples in the dataset\n",
        "total = np.sum(Dataset)\n",
        "\n",
        "# Initialize an empty dictionary to hold the weights\n",
        "class_weight = {}\n",
        "\n",
        "# Dynamically calculate the weight for each class\n",
        "for i in range(len(Dataset)):\n",
        "    class_weight[i] = (total / (len(Dataset) * Dataset[i]))\n",
        "\n",
        "# Print the computed weights for each class\n",
        "for class_id, weight in class_weight.items():\n",
        "    print(f'Weight for class {class_id}: {weight:.2f}')\n",
        "\n",
        "# Output the class weights dictionary\n",
        "print(class_weight)"
      ],
      "metadata": {
        "id": "oFaIi7NIoXuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## change hyperparameter such as epoches ## EnsembleNet3: Resnet, efficientnet, densenet\n",
        "history = ensemble_model.fit(train_dataset , verbose=2 , epochs=13 , class_weight=class_weight ,\n",
        "                               validation_data=valid_dataset , use_multiprocessing= True,callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "x_8uix2GoZip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_model.evaluate(test_dataset , verbose = 1)"
      ],
      "metadata": {
        "id": "hdCES8mdobNr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}